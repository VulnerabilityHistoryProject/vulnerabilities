CVE: CVE-2014-8541
yaml_instructions: |
  ===YAML Primer===
  This is a dictionary data structure, akin to JSON.
  Everything before a colon is a key, and the values here are usually strings

  For one-line strings, you can just use quotes after the colon

  For multi-line strings, as we do for our instructions, you put a | and then
  indent by two spaces.

  For readability, we hard-wrap multi-line strings at 80 characters. This is
  not absolutely required, but appreciated.
  === End YAML Primer===
curated_instructions: |
  If you are manually editing this file, then you are "curating" it.
  This will enable additional integrity checks on this file to make sure you
  fill everything out properly.

  IMPORTANT: If you are a student, we cannot accept your work as finished unless
  curation_level is properly set.

  The latest curation level is 1.0.
  If you are curating this vulnerability, set it to the latest curation level.
curation_level: 1.0
reported_instructions: |
  What date was the vulnerability reported to the security team? Look at the
  security bulletins, bug reports, commit messages of the fix.

  Reported date is likely the same as announced and published. Leave blank if
  you can't find it out.

  Please enter your date in YYYY-MM-DD format.
reported_date: 2014-11-05
announced_instructions: |
  Was there a date that this vulnerability was announced to the world? You can
  find this in changelogs, blogs, bug reports, or perhaps the CVE date.

  A good source of this for FFmpeg are their version numbers traced to tags:

    https://ffmpeg.org/security.html
    https://github.com/FFmpeg/FFmpeg/releases


  Please enter your date in YYYY-MM-DD format.
announced_date: 2014-11-05T11:55Z
published_instructions: |
  Is there a published fix or patch date for this vulnerability?
  Please enter your date in YYYY-MM-DD format.
published_date: 2014-11-05T11:55Z
description_instructions: |
  You can get an initial description from the CVE entry on cve.mitre.org. These
  descriptions are a fine start, but they can be kind of jargony.

  Rewrite this description IN YOUR OWN WORDS. Make it interesting and easy to
  read to anyone with some programming experience. We can always pull up the NVD
  description later to get more technical.

  Try to still be specific in your description, but remove project-specific
  stuff. Remove references to versions, specific filenames, and other jargon
  that outsiders to this project would not understand. Technology like "regular
  expressions" is fine, and security phrases like "invalid write" are fine to
  keep too.

  Your target audience is people just like you before you took any course in
  security
description: |
  A vulnerability in mpeg video decoding, where the decoder will only keep track
  of image size changes through the set "dimensions" of each frame's image (and
  not accounting for the "bits per pixel" of the frame). This allows remote
  attackers to make use of data with non-standard bytes-per-pixel in order to
  over or underflow the backing memory buffer.

  The bits-per-pixel has to do with the eventual bit-width of what you read for
  a pixel's value. In RGB you could have 3 ints, which could individually be
  32 bits, or 16 bits, etc. By setting an amount per-pixel (as opposed to or in
  addition to the dimensions), ffmpeg won't know how many bits to read at each
  pixel from the input. Naturally if you expect N pixels but only get N/2, you
  will end up reading another N/2 of overflow memory.
bounty_instructions: |
  If you came across any indications that a bounty was paid out for this
  vulnerability, fill it out here. Or correct it if the information already here
  was wrong. Otherwise, leave it blank.
bounty:
  amt:
  announced:
  url:
bugs_instructions: |
  Are there any bug reports that trace to this vulnerability?

  Sometimes a commit message will mention a bug, or the security page on FFmpeg.
  Sometimes you need to search bug database, which is here:
      https://trac.ffmpeg.org
bugs: []
fixes_vcc_instructions: |
  Please put the commit hash in "commit" field below (see my example in
  CVE-2011-3092.yml).

  Fixes and VCCs follow the same format - they are arrays of hashes.

  The notes field is optional - place anything that clarifies things or you
  find interesting in there.
fixes:
- commit: 5c378d6a6df8243f06c87962b873bd563e58cd39
  note: 'Found By: Mateusz "j00ru" Jurczyk and Gynvael Coldwind'
- commit: ''
  note: ''
vccs:
- commit: 4922a5b0ee9108e406b8b14356f19851702604d1
  note: |
    Identified by archeogit,Identified by SZZUnleashed
    a refactoring of a class into two new modules
- commit: 10b7b472d99b8db3fba287388294dae7ce89f152
  note: The earliest point in the mpeg-coder history that decoding was added w/ the bug
- commit: ''
  note: ''
upvotes_instructions: |
  For the first round, ignore this upvotes number.

  For the second round of reviewing, you will be giving a certain amount of
  upvotes to each vulnerability you see. Your peers will tell you how
  interesting they think this vulnerability is, and you'll add that to the
  upvotes score on your branch.
upvotes: 2
lifetime:
  question: |
    We consider the "lifetime" of this vulnerability to be from the earliest
    VCC to the latest fix.

    How would you characterize the development of this vulnerable code during
    its lifetime? Many new features? Neglected? One developer?
    Massive refactoring? Changing big dependencies?
    Changing architectures or language?


    What about the time period for the project itself?
    Did it undergo big changes during this time?

    Look at:
      * the commit messages between the two, using a command like
          git log --stat abc..def -- your/file.c
          (where a)
      * the changelog between the two
  answer: |
    VCC1 Date:  Thu May 17 16:29:11 2007 +0000
    VCC2 Date:  Mon Jan 19 15:46:40 2009 +0000
    Fix Date:   Fri Oct 3 01:50:27 2014 +0200
    Lifetime:   ~7 years

    Code has seen frequent and active development, with the project openly
    accepting PRs (and thus having collaborative code from 34 different authors,
    within the timeframe of VCC1->Fix). A majority of this commits are still
    michaelni (200+), with four other developers having over 10 commits to the
    history in this timeframe. FFMpeg itself went through several early
    revisions, beta and initial releases, and several lifecycle phases before
    this issue was fully addressed.
unit_tested:
  question: |
    Were automated unit tests involved in this vulnerability?
    Was the original code unit tested, or not unit tested? Did the fix involve
    improving the automated tests?

    For code: and fix: - your answer should be boolean.

    For the code_answer below, look not only at the fix but the surrounding
    code near the fix in related directories and determine if and was there were
    unit tests involved for this subsystem. The code

    For the fix_answer below, check if the fix for the vulnerability involves
    adding or improving an automated test to ensure this doesn't happen again.

    In FFmpeg, they have the FATE suite of regression tests. They are not
    "unit" tests per se, but are automated regression tests. If the fix for the
    vulnerability involved adding or updating a FATE suite, then make fix: true.
  code: false
  code_answer: No automated/regression tests, no updates to them in fixes.
  fix: false
  fix_answer: Code was updated/fixed directly, no FATE suite
discovered:
  question: |
    How was this vulnerability discovered?

    Find any relevant bug reports or mailing list conversations read the
    conversation to find out how this was
    originally found. Answer in longform below in "answer".

    If it's clear that the vulenrability was discovered by a
    contest, fill in the name of the contest in "answer".

    If it's clear that it was found by a developer of the project itself,
    e.g. from the email address or a previous committer.

    The automated, contest, and developer flags can be true, false, or nil.

    If there is no evidence as to how this vulnerability was found, then please
    explain where you looked. Thus, 'answer' should always have some
    explanation.
  answer: |
    End-user of the software had a file which failed to properly decode (caused
    a buffer overflow). While I could not find an attached ticket/issue, it
    seems there had been previous communication of this file, as well as
    previous commits concerning it. Thus it was essentially discovered through
    trial-and-error / community feedback.
  automated: false
  contest: false
  developer: false
autodiscoverable:
  instructions: |
    Is it plausible that a fully automated tool could have discovered
    this? These are tools that require little knowledge of the domain,
     e.g. automatic static analysis, compiler warnings, fuzzers.

    Examples for true answers: SQL injection, XSS, buffer overflow,
    use-after-free

    Examples for false: specification violations, permissions issues, anything
    that would require a tool to be "aware" of the project's
    domain-specific requirements.

    The answer field should be boolean. In answer_note, please explain
    why you come to that conclusion.
  answer_note: |
    Requires specifically crafted input, more likely to be found accidentally.
    In this case, this bug was found because a method was available that, with
    the correctly formed input, would cause a buffer overflow. In practice,
    this was not exploitable in production code as the parameter received a
    bitlength of a number up to 16 bits (1 through 16); it could never overflow.
    However, the potential for the overflow to occur in future changes is still
    there.
  answer: false
specification:
  instructions: |
    Is there mention of a violation of a specification? For example,
    an RFC specification, a protocol specification, codec spec, or a requirements
    specification.

    Be sure to check all artifacts for this: bug report, security
    advisory, commit message, etc.

    The answer field should be boolean. In answer_note, please explain
    why you come to that conclusion.
  answer_note: |
    While I could not find any explicit reference to a standard or specification,
    the crash did center around the format for input MPEG-video frames, which is
    likely standardized and published somewhere.
  answer: false
subsystem:
  question: |
    What subsystems was the mistake in?

    Look at the path of the source code files code that were fixed to get
    directory names. Look at comments in the code. Look at the bug reports how
    the bug report was tagged.

    In FFmpeg, the Component field is useful here. Often people will say
      "undetermined" - do more homework than them and make a judgement call if
      you can.

    Note: a filepath is NOT a subsystem - that's too granular.

    A non-exhaustive examples for ffmpeg are:
      * avcodec
      * avdevice
      * avfilter
      * avformat
      * avutil
      * build system
      * documentation
      * fate
      * ffplay
      * ffprobe
      * postproc
      * swresample
      * swscale
      * tools
      * trac
      * website

    If this involves fixing multiple subsystems, you can make this an array.

    In 'answer', explain how you arrived at this determination.
  answer: |
    The video decoder for .avi/mpeg (MJpegDecodeContent) is handled within
    mjpegdec.c, safely within libavcodec (which handles encoding/decoding
    specifications).
  name: avcodec
interesting_commits:
  question: |
    Optional: are there any interesting commits between your VCC(s) and fix(es)?

    Write a brief (under 100 words) description of why you think this commit was
    interesting in light of the lessons learned from this vulnerability. Any
    emerging themes?

    This is a catch-all for any interesting commit you find.
    Example of interesting commits:
      * Giant refactors
      * Changing an API or big dependency
      * A change that looks really sketchy
      * Commits where a developer mentions security in their message or comments
  commits:
  - commit: 0db1f2c2c78db18999fccd46a156408e5e87c8a1
    note: 'A related commit, perhaps early attempts at a fix/debugging'
  - commit: ''
    note: ''
i18n:
  question: |
    Was the feature impacted by this vulnerability about internationalization
    (i18n)? An internationalization feature is one that enables people from all
    over the world to use the system. This includes translations, locales,
    typography, unicode, or various other features.

    Answer should be boolean. Write a note about how you came to the conclusions
    you did.
  answer: false
  note: |
    While the various types (and implementations) of codecs are themselves an
    internationalization issue, this specific issue does not arise from
    internationalization concerns in the context of what we are seeking (in
    relation to character sets, text encoding, etc).
ipc:
  question: |
    Did the feature that this vulnerability affected use inter-process
    communication? IPC includes OS signals, pipes, stdin/stdout, message
    passing, and clipboard. Writing to files that another program in this
    software system reads is another form of IPC.

    Answer should be boolean.
  answer: true
  note: |
    Absolutely, interacts with MJpegDecodeContext, which is fed from user input,
    and then output to any variety of locations specified by the end-user.
lessons:
  question: |
    Are there any common lessons we have learned from class that apply to this
    vulnerability? In other words, could this vulnerability serve as an example
    of one of those lessons?

    Leave "applies" blank or put false if you did not see that lesson (you do
    not need to put a reason). Put "true" if you feel the lesson applies and put
    a quick explanation of how it applies.

    Don't feel the need to claim that ALL of these apply, but it's pretty likely
    that one or two of them apply.

    If you think of another lesson we covered in class that applies here, feel
    free to give it a small name and add one in the same format as these.
  defense_in_depth:
    applies: true
    note: |
      In this sense, defense in depth would be good to apply
      towards the encoder/decoder modules, as failure within a module
      could be isolated and reported. Particularly as these are
      open-source modules, some isolation is desired.
  least_privilege:
    applies:
    note:
  frameworks_are_optional:
    applies:
    note:
  native_wrappers:
    applies:
    note:
  distrust_input:
    applies: true
    note: |
      As always, if this system is user-facing and accepts input, it will
      likely be compromised if it is capable of being so. In this case,
      once a user has found an input that crashes the system, there's no
      stopping them from holding down the service.
  security_by_obscurity:
    applies:
    note:
  serial_killer:
    applies:
    note:
  environment_variables:
    applies:
    note:
  secure_by_default:
    applies:
    note:
  yagni:
    applies:
    note:
  complex_inputs:
    applies: true
    note: |
      Videos easily fall under complex inputs, codec-specific information caused
      this crash
mistakes:
  question: |
    In your opinion, after all of this research, what mistakes were made that
    led to this vulnerability? Design mistakes? Maintainability? Requirements?
    Miscommunications? Lack of testing? Lack of understanding? Lack of
    specifications? Working alone?

    An answer like "it was just a coding mistake" is not thoughtful enough.
    If it's such an easy mistake to make, how was it missed?

    Also, look at the CWE entry for this vulnerability and examine the mitigations
    they have written there. Are they doing those? Does the fix look proper?

    Use those questions to inspire your answer. Don't feel obligated to answer
    every one. Write a thoughtful entry here that those ing the software
    engineering industry would find interesting.
  answer: |
    Quite an old bug on this one! In truth, I think some more stringent
    controls in terms of unit testing as well as testing a larger variety of
    inputs would benefit in seeing some of the pitfalls. More importantly,
    these tests need to be kept up-to-date with current standards involved
    with the codecs' formats.

    To add to all of this, the developer did not consider the many forms of
    potential input into their system. The fact that the developer did not
    expect a difference in pixel sizes (perhaps not reading the specification)
    directly lead to this buffer overflow.
CWE_instructions: |
  Please go to http://cwe.mitre.org and find the most specific, appropriate CWE
  entry that describes your vulnerability. We recommend going to
  https://cwe.mitre.org/data/definitions/699.html for the Software Development
  view of the vulnerabilities. We also recommend the tool
  http://www.cwevis.org/viz to help see how the classifications work.

  If you have anything to note about why you classified it this way, write
  something in CWE_note. This field is optional.

  Just the number here is fine. No need for name or CWE prefix. If more than one
  apply here, then choose the best one and mention the others in CWE_note.
CWE: 119
CWE_note:
nickname_instructions: |
  A catchy name for this vulnerability that would draw attention it. If the
  report mentions a nickname, e.g. "Heartbleed", use that. Or come up with one!

  Must be under 30 characters. Optional. Be appropriate.
nickname: MPegged
CVSS: AV:N/AC:L/Au:N/C:P/I:P/A:P

